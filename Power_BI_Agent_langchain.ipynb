{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+RaUkE6dckz9gBOF5GuXl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srini-UK/GenAI_Assignments/blob/main/Power_BI_Agent_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install Required Package"
      ],
      "metadata": {
        "id": "9mhhl2SC7aa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit msal requests google-generativeai langchain matplotlib pyngrok"
      ],
      "metadata": {
        "id": "bX_2pAooUURn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Create\n",
        "Gemini + Power BI agent logic"
      ],
      "metadata": {
        "id": "ZbL7yghE7cq4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iJvEJe-K7MsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d16b756-3251-4bdd-bcb5-5fc34b388d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing agent.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile agent.py\n",
        "import requests\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "\n",
        "def run_agent_query(question: str, report_id: str, workspace_id: str, access_token: str, gemini_api_key: str, mode: str) -> str:\n",
        "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "    url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/reports/{report_id}\"\n",
        "    report_info = requests.get(url, headers=headers).json()\n",
        "    dataset_id = report_info.get(\"datasetId\")\n",
        "    sample_data = {}\n",
        "\n",
        "    if dataset_id:\n",
        "        tables_url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/datasets/{dataset_id}/tables\"\n",
        "        tables_response = requests.get(tables_url, headers=headers).json()\n",
        "        for table in [t[\"name\"] for t in tables_response.get(\"value\", [])][:2]:\n",
        "            rows_url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/datasets/{dataset_id}/tables/{table}/rows\"\n",
        "            rows_response = requests.get(rows_url, headers=headers).json()\n",
        "            sample_data[table] = rows_response.get(\"value\", [])[:5]\n",
        "\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "    if mode == \"Executive Summary\":\n",
        "        prompt = f\"\"\"\n",
        "        You are a business intelligence assistant reviewing a Power BI report.\n",
        "\n",
        "        User question:\n",
        "        \"{question}\"\n",
        "\n",
        "        Report metadata and sample data:\n",
        "        {json.dumps(report_info)}\n",
        "        {json.dumps(sample_data)}\n",
        "\n",
        "        Generate a narrative-style summary similar to Power BI Copilot:\n",
        "        - Highlight variance across regions, departments, and months\n",
        "        - Mention top and bottom performers\n",
        "        - Use realistic numbers and percentages\n",
        "        - Structure your response into clear sections\n",
        "        - End with a business recommendation\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        You are a technical Power BI assistant.\n",
        "\n",
        "        User question:\n",
        "        \"{question}\"\n",
        "\n",
        "        Report metadata and sample data:\n",
        "        {json.dumps(report_info)}\n",
        "        {json.dumps(sample_data)}\n",
        "\n",
        "        Provide a technical breakdown:\n",
        "        - Suggest DAX measures and filters\n",
        "        - Mention visuals that would help\n",
        "        - Avoid storytelling or business summaries\n",
        "        \"\"\"\n",
        "\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "    return {\n",
        "    \"text\": model.generate_content(prompt).text.strip(),\n",
        "    \"sample_data\": sample_data  # for charting\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Create\n"
      ],
      "metadata": {
        "id": "aCJVgqy6Uezs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ms_UIQ0VmGW",
        "outputId": "20e325be-27d0-4299-999a-6820336c7e10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=3fdc2265cac9179090bd33a3d377604ca39246776e2ecaa54a641d7094c44498\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/62/11/dc73d78e40a218ad52e7451f30166e94491be013a7850b5d75\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "import json\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "from agent import run_agent_query\n",
        "\n",
        "report_options = {\n",
        "    \"IT Spend Analysis\": {\n",
        "        \"workspace_id\": \"3750a12a-691c-4aac-8799-3ce40d992b53\",\n",
        "        \"report_id\": \"b94a016d-a8dd-4db6-8a1d-85cc37d3c99c\"\n",
        "    },\n",
        "    \"Sales Performance\": {\n",
        "        \"workspace_id\": \"your-other-workspace-id\",\n",
        "        \"report_id\": \"your-other-report-id\"\n",
        "    }\n",
        "}\n",
        "\n",
        "selected_report = st.selectbox(\"ðŸ“ Choose Power BI Report\", list(report_options.keys()))\n",
        "WORKSPACE_ID = report_options[selected_report][\"workspace_id\"]\n",
        "REPORT_ID = report_options[selected_report][\"report_id\"]\n",
        "\n",
        "# ðŸ”§ Replace these with your actual values\n",
        "TENANT_ID = \"4c7c1242-2420-473e-a5ab-856cb9e3ca20\"\n",
        "CLIENT_ID = \"b0188a7c-3af7-4a8a-b068-4758609e38c8\"\n",
        "CLIENT_SECRET = \"RDx8Q~we2J1D5E9CSvH9-OMH0f3MkUdFa8_zea8a\"\n",
        "WORKSPACE_ID = \"3750a12a-691c-4aac-8799-3ce40d992b53\"\n",
        "REPORT_ID = \"b94a016d-a8dd-4db6-8a1d-85cc37d3c99c\"\n",
        "GEMINI_API_KEY = \"AIzaSyAoWRS242ltOA-xJBVpkr9W56YXmCFnxjU\"\n",
        "\n",
        "# ðŸ” Authenticate with Power BI\n",
        "SCOPE = [\"https://analysis.windows.net/powerbi/api/.default\"]\n",
        "from msal import ConfidentialClientApplication\n",
        "app_auth = ConfidentialClientApplication(\n",
        "    CLIENT_ID,\n",
        "    authority=f\"https://login.microsoftonline.com/{TENANT_ID}\",\n",
        "    client_credential=CLIENT_SECRET\n",
        ")\n",
        "ACCESS_TOKEN = app_auth.acquire_token_for_client(scopes=SCOPE).get(\"access_token\")\n",
        "\n",
        "# ðŸŽ›ï¸ Streamlit UI\n",
        "st.set_page_config(page_title=\"Power BI Q&A Agent\", page_icon=\"ðŸ“Š\")\n",
        "st.title(\"ðŸ’¬ Power BI Interactive Q&A Agent\")\n",
        "st.markdown(\"Ask questions about your Power BI report and choose your insight style:\")\n",
        "\n",
        "if \"qa_history\" not in st.session_state:\n",
        "    st.session_state.qa_history = []\n",
        "\n",
        "mode = st.radio(\"Choose insight style:\", [\"Executive Summary\", \"Technical Breakdown\"])\n",
        "question = st.text_area(\"Type your question:\")\n",
        "\n",
        "if st.button(\"Submit Question\") and question.strip():\n",
        "    with st.spinner(\"Generating insight...\"):\n",
        "        result = run_agent_query(\n",
        "            question=question,\n",
        "            report_id=REPORT_ID,\n",
        "            workspace_id=WORKSPACE_ID,\n",
        "            access_token=ACCESS_TOKEN,\n",
        "            gemini_api_key=GEMINI_API_KEY,\n",
        "            mode=mode\n",
        "        )\n",
        "        insight_text = result[\"text\"]\n",
        "        sample_data = result.get(\"sample_data\", {})\n",
        "\n",
        "        st.session_state.qa_history.append({\n",
        "            \"question\": question,\n",
        "            \"mode\": mode,\n",
        "            \"insight\": insight_text\n",
        "        })\n",
        "\n",
        "if st.session_state.qa_history:\n",
        "    st.subheader(\"ðŸ§  Q&A History\")\n",
        "    for i, qa in enumerate(reversed(st.session_state.qa_history), 1):\n",
        "        with st.expander(f\"{qa['mode']} | Question {len(st.session_state.qa_history) - i + 1}: {qa['question']}\"):\n",
        "            st.markdown(\"**ðŸ’¡ Insight:**\")\n",
        "            st.write(qa[\"insight\"])\n",
        "                    # ðŸ“Š Dynamic Charts from Sample Data\n",
        "        if \"sample_data\" in qa and qa[\"sample_data\"]:\n",
        "            st.subheader(\"ðŸ“Š Dynamic Charts from Power BI\")\n",
        "            for table, rows in qa[\"sample_data\"].items():\n",
        "                st.markdown(f\"**Table: {table}**\")\n",
        "                if rows and isinstance(rows[0], dict):\n",
        "                    keys = list(rows[0].keys())\n",
        "                    if len(keys) >= 2:\n",
        "                        x = [str(row[keys[0]]) for row in rows]\n",
        "                        y = [float(row[keys[1]]) if isinstance(row[keys[1]], (int, float)) else 0 for row in rows]\n",
        "                        fig, ax = plt.subplots()\n",
        "                        ax.bar(x, y)\n",
        "                        ax.set_xlabel(keys[0])\n",
        "                        ax.set_ylabel(keys[1])\n",
        "                        ax.set_title(f\"{table}: {keys[1]} by {keys[0]}\")\n",
        "                        st.pyplot(fig)\n",
        "\n",
        "# ðŸ“¤ Export to Markdown\n",
        "def generate_markdown_export(history):\n",
        "    md = \"# Power BI Q&A History\\n\\n\"\n",
        "    for i, qa in enumerate(history, 1):\n",
        "        md += f\"## Question {i}: {qa['question']}\\n\\n\"\n",
        "        md += f\"**Mode:** {qa['mode']}\\n\\n\"\n",
        "        md += f\"**Insight:**\\n\\n{qa['insight']}\\n\\n\"\n",
        "    return md\n",
        "\n",
        "def download_button(label, content, filename):\n",
        "    b64 = base64.b64encode(content.encode()).decode()\n",
        "    href = f'<a href=\"data:file/txt;base64,{b64}\" download=\"{filename}\">{label}</a>'\n",
        "    st.markdown(href, unsafe_allow_html=True)\n",
        "\n",
        "if st.session_state.qa_history:\n",
        "    st.subheader(\"ðŸ“¤ Export Options\")\n",
        "    markdown = generate_markdown_export(st.session_state.qa_history)\n",
        "    download_button(\"â¬‡ï¸ Download as Markdown\", markdown, \"powerbi_insights.md\")\n",
        "\n",
        "from fpdf import FPDF\n",
        "\n",
        "def generate_pdf_export(history):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(200, 10, txt=\"Power BI Q&A History\", ln=True, align=\"C\")\n",
        "\n",
        "    for i, qa in enumerate(history, 1):\n",
        "        pdf.set_font(\"Arial\", style=\"B\", size=12)\n",
        "        pdf.multi_cell(0, 10, f\"Question {i}: {qa['question']}\")\n",
        "        pdf.set_font(\"Arial\", style=\"\", size=11)\n",
        "        pdf.multi_cell(0, 10, f\"Mode: {qa['mode']}\")\n",
        "        pdf.multi_cell(0, 10, f\"Insight:\\n{qa['insight']}\\n\")\n",
        "\n",
        "    pdf.output(\"powerbi_insights.pdf\")\n",
        "\n",
        "if st.session_state.qa_history:\n",
        "    if st.button(\"â¬‡ï¸ Generate PDF\"):\n",
        "        generate_pdf_export(st.session_state.qa_history)\n",
        "        st.success(\"PDF saved as powerbi_insights.pdf\")\n",
        "\n",
        "# ðŸ“Š Sample Chart\n",
        "def plot_variance_example():\n",
        "    categories = [\"USA\", \"Germany\", \"UK\", \"Italy\", \"Brazil\"]\n",
        "    variance = [12.89, 3.2, 2.5, -5.1, -6.3]\n",
        "    fig, ax = plt.subplots()\n",
        "    bars = ax.bar(categories, variance, color=[\"green\" if v > 0 else \"red\" for v in variance])\n",
        "    ax.set_ylabel(\"Variance from Plan ($M)\")\n",
        "    ax.set_title(\"Regional IT Spend Variance\")\n",
        "    st.pyplot(fig)\n",
        "\n",
        "if st.checkbox(\"ðŸ“Š Show Sample Variance Chart\"):\n",
        "    plot_variance_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4KIPAWQU9eX",
        "outputId": "7dfdbc38-c48e-4477-d0bd-8cb6a06db756"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch Streamlit in Colab"
      ],
      "metadata": {
        "id": "ONOJeLDKVBXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# Start Streamlit in background\n",
        "get_ipython().system_raw('streamlit run app.py &')\n",
        "time.sleep(5)\n",
        "\n",
        "# Open tunnel\n",
        "ngrok.set_auth_token(\"34tDSHi4VdZGx5IN7f8Gcp5uYs9_2PoXTHSNv67asekCtnQv2\")  # ðŸ”§ Replace with actual token\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸ”— Streamlit app is live at:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh4ViMw2VKE0",
        "outputId": "fd7ff8ab-66f6-40ab-a4cf-e49337754b58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.4.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "ðŸ”— Streamlit app is live at: NgrokTunnel: \"https://spookiest-noncomically-claudia.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "C5cr_QkR7dHQ"
      }
    }
  ]
}