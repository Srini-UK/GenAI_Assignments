{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7hbMArLjObXcYwhBMt/+Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srini-UK/GenAI_Assignments/blob/main/LangChain_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install LangChain"
      ],
      "metadata": {
        "id": "OieZLRm6NPIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuL_Sch5NIno"
      },
      "outputs": [],
      "source": [
        "!pip install langchain google-generativeai msal requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Gemini Tool"
      ],
      "metadata": {
        "id": "-Dw4WwKONeA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n",
        "\n",
        "@tool\n",
        "def ask_gemini(question: str, metadata: str) -> str:\n",
        "    \"\"\"Use Gemini to answer a BI question based on metadata and sample data.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "    prompt = f\"\"\"\n",
        "    You are a BI assistant. Answer the question using the metadata below.\n",
        "\n",
        "    Question: {question}\n",
        "    Metadata: {metadata}\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()"
      ],
      "metadata": {
        "id": "1FBYX9pANfy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Power BI Tool"
      ],
      "metadata": {
        "id": "z05F2u6NNri0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def fetch_powerbi_metadata(report_id: str, workspace_id: str, access_token: str) -> str:\n",
        "    \"\"\"Fetch Power BI report metadata and sample data.\"\"\"\n",
        "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "    url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/reports/{report_id}\"\n",
        "    report_info = requests.get(url, headers=headers).json()\n",
        "    dataset_id = report_info.get(\"datasetId\")\n",
        "    sample_data = {}\n",
        "\n",
        "    if dataset_id:\n",
        "        tables_url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/datasets/{dataset_id}/tables\"\n",
        "        tables_response = requests.get(tables_url, headers=headers).json()\n",
        "        for table in [t[\"name\"] for t in tables_response.get(\"value\", [])][:2]:\n",
        "            rows_url = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspace_id}/datasets/{dataset_id}/tables/{table}/rows\"\n",
        "            rows_response = requests.get(rows_url, headers=headers).json()\n",
        "            sample_data[table] = rows_response.get(\"value\", [])[:5]\n",
        "\n",
        "    return json.dumps({\"report\": report_info, \"sample\": sample_data})"
      ],
      "metadata": {
        "id": "t2T-T8iVNyu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build LangChain Agent"
      ],
      "metadata": {
        "id": "PpFGLarsN1GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import GoogleGenerativeAI\n",
        "\n",
        "llm = GoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=\"YOUR_GEMINI_API_KEY\")\n",
        "\n",
        "tools = [ask_gemini, fetch_powerbi_metadata]\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "XmVoShExN5q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Agent"
      ],
      "metadata": {
        "id": "SMFdc80VN-iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your actual values\n",
        "ACCESS_TOKEN = \"your-access-token\"\n",
        "WORKSPACE_ID = \"your-workspace-id\"\n",
        "REPORT_ID = \"your-report-id\"\n",
        "\n",
        "response = agent.run(f\"\"\"\n",
        "Fetch Power BI metadata for report {REPORT_ID} in workspace {WORKSPACE_ID} using access token {ACCESS_TOKEN},\n",
        "then answer: What was the IT spend for BU Support in January 2014 for the USA region?\n",
        "\"\"\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Y9MzTAPgOC4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}